{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4d81fe",
   "metadata": {},
   "source": [
    "# Save the weather details drought information for every county that had a wildfire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d17e9",
   "metadata": {},
   "source": [
    "## Install the Python requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas==1.3.2\n",
    "pip install tqdm==4.62.2\n",
    "pip install psycopg2-binary==2.9.1\n",
    "pip install sqlalchemy==1.4.23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69950657",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c12ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import requests\n",
    "import psycopg2\n",
    "import http.client\n",
    "import os\n",
    "\n",
    "from io import StringIO\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from requests.exceptions import ConnectionError\n",
    "\n",
    "from tqdm.auto import tqdm  # for notebooks\n",
    "from amazon_cred import ENDPOINT, PORT, USER, PASSWORD, DATABASE\n",
    "\n",
    "from data_constants import ZONE_COUNTY_CORR_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d52831",
   "metadata": {},
   "source": [
    "## Constant URLs, storm categories, and strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3fdec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "USDM_CSV_BASE_URL = 'https://droughtmonitor.unl.edu/DmData/GISData.aspx?mode=table&aoi=county&date='\n",
    "\n",
    "NCDC_TOKEN = '***REMOVED***'\n",
    "NCDC_BASE_URL = 'www.ncdc.noaa.gov'\n",
    "NCDC_WEATHER_STATIONS_LST_URL = '/cdo-web/api/v2/stations?locationid=FIPS:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dfb8235",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a108e917e1b143d0a0c741bcd1625b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7187e74673db45f792f6cacfc269d353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No weather record found for  SAN MIGUEL, NEW MEXICO  out of  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb443c9d5fd341519c541cfaa2170970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5302c1d6f8774a6fb463a844c24b34d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aba510c35c54d178c88057971bd43b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89f7437886b4563be2370533b01732e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No weather record found for  FORSYTH, GEORGIA  out of  2\n",
      "No weather record found for  DOUGLAS, GEORGIA  out of  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4790a72d1564ecabf74c7a37fc993d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d5cc5b2387453da70dde2a943e0f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e7c5806e234f3d918fbc77d7954c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No weather stations found  NORTHAMPTON, PENNSYLVANIA\n",
      "No weather record found for  GREATER LAKE TAHOE AREA, CALIFORNIA  out of  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6ef7da767b4890905c34bd631c5afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No weather record found for  WISE, TEXAS  out of  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dbefe89d9d40d1a0e5ddd3a4eaf2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112413a4c5ad4afdba4f905818d08d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_zone_county = pd.read_csv(ZONE_COUNTY_CORR_URL, sep='|', header=None,\n",
    "                    names=['STATE', 'ZONE', 'CWA', 'NAME', 'STATE_ZONE',\n",
    "                           'CZ_NAME', 'FIPS', 'TIME_ZONE', 'FE_AREA', 'LAT', 'LON'])\n",
    "df_zone_county = df_zone_county[['FIPS', 'LAT', 'LON']]\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    metric_constant = 3959\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1,lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    haversine_distance = metric_constant * c\n",
    "    return haversine_distance\n",
    "\n",
    "def closestn(df_stations, county, n=3):\n",
    "    def calc_haversine(row):\n",
    "        row['hav'] = haversine(row['latitude'], row['longitude'], county['LAT'], county['LON'])\n",
    "        return row\n",
    "    df_stations = df_stations.apply(calc_haversine, axis=1)\n",
    "    return df_stations.nsmallest(n, ['hav'])\n",
    "\n",
    "def donwload_climate_info(station_number, start_date, end_date):\n",
    "    api =  f'https://www.ncei.noaa.gov/access/services/data/v1.?dataset=daily-summaries&stations={station_number}'\n",
    "    api += f'&startDate={start_date}&endDate={end_date}&units=metric'\n",
    "    while True:\n",
    "        try:\n",
    "            res = requests.get(api, timeout=5)\n",
    "            break\n",
    "        except ConnectionError:\n",
    "            print('Connection error')\n",
    "    return res.content\n",
    "\n",
    "\n",
    "def getWildFireEvents(year):\n",
    "    wildfire = \"'Wildfire'\"    \n",
    "    conn = psycopg2.connect(\n",
    "        host=ENDPOINT,\n",
    "        port=PORT,\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        database = DATABASE\n",
    "    )\n",
    "    with conn:\n",
    "        select = f'SELECT * from counties WHERE \"Year\" = {year} AND \"EVENT_TYPE\" = {wildfire}'\n",
    "        df_counties = pd.read_sql(select, con=conn)\n",
    "    conn.close()\n",
    "    \n",
    "    os.mkdir(str(year))\n",
    "    # print(\"Processing : \", df_counties.shape[0], \" for \", str(year))\n",
    "    for r, row in tqdm(df_counties.iterrows()):\n",
    "        today = row['EVENT_DATE']\n",
    "        dirname = str(year) + '/' + today.strftime('%m_%d') + '_' + row['FIPS']\n",
    "        if os.path.exists(dirname):\n",
    "            continue # we already have the county weather\n",
    "    \n",
    "        os.mkdir(dirname)\n",
    "\n",
    "        offset = (today.weekday() - 1)%7\n",
    "        last_tuesday = today - timedelta(days=offset)\n",
    "        twelve_years_past = last_tuesday - timedelta(days=12*365.25) # request for additional data\n",
    "        twelve_years_str = twelve_years_past.strftime('%Y-%m-%d')\n",
    "        last_tuesday_str = last_tuesday.strftime('%Y-%m-%d')\n",
    "\n",
    "        r = requests.get(USDM_CSV_BASE_URL+last_tuesday_str)\n",
    "        content = r.content.decode('utf-8')\n",
    "        df_usdm = pd.read_csv(StringIO(content))\n",
    "\n",
    "        df_usdm.to_csv(dirname + '/' + 'usdm.csv')\n",
    "\n",
    "        #df_usdm['FIPS'] = df_usdm['FIPS'].astype(str) # cast it as string in order to zfill\n",
    "        #df_usdm['FIPS'] = df_usdm['FIPS'].apply(lambda x: x.zfill(5)) # no need to zfill\n",
    "\n",
    "        df_usdm_merged = df_usdm.merge(df_zone_county, on=['FIPS'])\n",
    "        wildfire_county_df = df_usdm_merged[df_usdm_merged['FIPS'] == int(row['FIPS'])]\n",
    "\n",
    "        # Precipitation data\n",
    "        # list of weather stations using NCDC api: https://www.ncdc.noaa.gov/cdo-web/webservices/v2#gettingStarted\n",
    "        headers = {'token': NCDC_TOKEN}\n",
    "        conn_http = http.client.HTTPSConnection(NCDC_BASE_URL)\n",
    "        conn_http.request('GET', NCDC_WEATHER_STATIONS_LST_URL + row['FIPS'] + \n",
    "                     f'&startdate={twelve_years_str}&enddate={last_tuesday_str}&limit=100' +\n",
    "                     '&dataset=GHCND&datacategoryid=TEMP,PRCP', # Daily summaries of temperature and precipitation\n",
    "                     headers=headers)\n",
    "\n",
    "        result = conn_http.getresponse()\n",
    "        result = result.read()\n",
    "        # somehow curl does not allow me to redirect output.\n",
    "        #!curl -H \"token:***REMOVED***\" \"https://www.ncdc.noaa.gov/cdo-web/api/v2/stations?locationid=FIPS:08049\"\n",
    "\n",
    "        data = json.loads(result)\n",
    "        try:\n",
    "            df_stations = pd.DataFrame(data[\"results\"])\n",
    "        except KeyError:\n",
    "            print(\"No weather stations found \", row['NAME'])\n",
    "            continue\n",
    "        \n",
    "        # print(df_stations.shape[0], \" df_stations found\")\n",
    "\n",
    "        df_stations['mindate'] = pd.to_datetime(df_stations['mindate'])\n",
    "        df_stations['maxdate'] = pd.to_datetime(df_stations['maxdate'])\n",
    "        df_stations = df_stations[(df_stations['mindate'] <= twelve_years_past) &\n",
    "                                  (df_stations['maxdate'] >= last_tuesday)]\n",
    "        # print(\"df_stations: \", df_stations.shape[0])\n",
    "        if df_stations.shape[0]:\n",
    "            last_10_yr_date = last_tuesday - timedelta(days=10*365.25)\n",
    "            last_10_yr_date = pd.to_datetime(str(last_10_yr_date.year) + '-01-01')\n",
    "            last_10_yr_date_str = last_10_yr_date.strftime('%Y-%m-%d')\n",
    "\n",
    "            df_closestn = closestn(df_stations, wildfire_county_df.iloc[0])\n",
    "            foundRec = False\n",
    "            for _, row_c in df_closestn.iterrows():\n",
    "                id_gnd = row_c['id'].split(':')\n",
    "                # print(id_gnd[1])\n",
    "                response = donwload_climate_info(id_gnd[1], last_10_yr_date_str, last_tuesday_str)\n",
    "\n",
    "                df_weather = pd.read_csv(StringIO(response.decode(\"UTF-8\")))[['DATE', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN']]\n",
    "                df_copy = df_weather.copy()\n",
    "                df_copy.dropna(subset=['TMIN','TMAX','PRCP'], inplace=True)\n",
    "                # print(df_weather.shape[0], last_10_yr_date_str, last_tuesday_str)\n",
    "                if df_copy.shape[0] <= (0.5*df_weather.shape[0]): # 50 % of the records missing!\n",
    "                    continue\n",
    "                else:\n",
    "                    df_weather['DATE'] = pd.to_datetime(df_weather['DATE'])\n",
    "                    foundRec = True\n",
    "                    break\n",
    "            if not foundRec:\n",
    "                print(\"No weather record found for \", row['NAME'], \" out of \", df_closestn.shape[0])\n",
    "            \n",
    "            # Fill in the missing dates with np.NaN\n",
    "            df_weather.set_index('DATE', inplace=True)\n",
    "            idx = pd.date_range(last_10_yr_date_str, today.strftime('%Y-%m-%d'))\n",
    "            df_weather = df_weather.reindex(idx, fill_value = np.NaN)\n",
    "            df_weather.reset_index(inplace=True)\n",
    "            df_weather.rename(columns={'index':'DATE'}, inplace=True)\n",
    "            \n",
    "            # Save it to a CSV file instead of database\n",
    "            df_weather.to_csv(dirname + '/weather.csv', index = False)\n",
    "    \n",
    "    return\n",
    "\n",
    "start_year = 2000\n",
    "end_year = 2011\n",
    "for i in tqdm(range(start_year, end_year)):\n",
    "    getWildFireEvents(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
